{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('webscraper': conda)",
   "display_name": "Python 3.8.5 64-bit ('webscraper': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ee1bcffc68cbb7719a6612a6e77ce6a77f4c8bd47b1c2e1622f285909b582ca8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "import multiprocessing.dummy as mp\n",
    "URL = 'http://www.eprbulletsafsc.com/'\n",
    "outdir = '../scrapes/'\n",
    "outfile = outdir + 'eprbulletsafsc.txt'\n",
    "homepage = requests.get(URL)\n",
    "\n",
    "# need HTML5LIB because sometimes website has errors in HTML. html5lib is very forgiving.\n",
    "homeSoup = BeautifulSoup(homepage.content,'html5lib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageList = homeSoup.find(id='page').find_all('a', href=re.compile('\\w+\\.htm*'))\n",
    "# filtering out disclaimer link\n",
    "pageList = list(filter(lambda a: a['href'] != \"disclaimer.htm\", pageList))\n",
    "# some of the hrefs have '/' in front of them, but I don't think that will matter.\n",
    "\n",
    "pageURLs = [URL + pageItem['href'] for pageItem in pageList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBulletsInPage(pageURL, bulletDict):\n",
    "    \n",
    "    page = requests.get(pageURL)\n",
    "    pageSoup = BeautifulSoup(page.content, 'html5lib')\n",
    "\n",
    "    # Searches #bulletmain for all strings that match regex.\n",
    "    bulletScrape = pageSoup.find(id=\"page\").find_all(string=re.compile('^-\\s+.*'))\n",
    "    bulletDict[pageURL]  = [bullet.strip() for bullet in bulletScrape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multiprocessing is used to speed up the scrape. \n",
    "\n",
    "# a dict/manager is used to collect all scraped bullets during multiprocessing.  \n",
    "manager = mp.Manager()\n",
    "resultsDict = manager.dict()\n",
    "\n",
    "#running Pool() with no arguments will default to amount of cores you have... I think\n",
    "p = mp.Pool()\n",
    "\n",
    "p.starmap(getBulletsInPage, [(pageURL,resultsDict) for pageURL in pageURLs])\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "# Writing to file. Should default to clobbering.\n",
    "with open(outfile,'w',encoding='utf-8') as fileID:\n",
    "    for key in resultsDict:\n",
    "        fileID.write(f'SECTION {key} \\n')\n",
    "        for line in resultsDict[key]:\n",
    "            fileID.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&quot;- Oversaw MICT utilization effort; trained shop personnel on new inspection sys--ensured shop&#39;s 100% info accuracy&quot;,\n &#39;- Performed XX tool box inspections; verified XK tools serviceable/fixed XX--saved sqdn XXK in replacement parts&#39;,\n &#39;- Managed tool crib ops 228 hrs; ordered $9.3K parts/issued 872 CTK tools--100% accounted/0 FOD incidents&#39;,\n &#39;- Oversaw relocation of CTK; $400K+ worth of equipment moved--guaranteed seamless maintenance support&#39;,\n &#39;- Monitored/tracked $3M+ in CTKs/testers; 80 inspections completed--facilitated 98% AME in-commission rate&#39;,\n &quot;- Mng&#39;d dply&#39;d CTK assets; led 100% equip insp tm/ID&#39;d/rect 10 discreps--key to AOR 433 sorties/2.7K flt hrs FY &#39;16&quot;,\n &#39;- Section CTK Prgm Mgr; revamped TAS tracking identification/tool location...guaranteed 100% accountability&#39;,\n &quot;- Prepped section for 2011 LCAT visit; insp&#39;d tool kit w/zero defects noted--key to sq&#39;s 83% compliance rate&quot;,\n &quot;- Design/orchestrated $18K barebase &amp; C2 UTC general mx tool kit procurement; inc&#39;d Wg&#39;s mx capability 40%&quot;,\n &#39;- Reorganized $800K/15K item Consolidated Tool Kit prgm; no lost tools noted--achieved 100% QA pass rate&#39;,\n &#39;- Inspected 120 tool kits; cleaned/serviced 3.6K tools--provided serviceable tools for critical LO restoration&#39;,\n &quot;- Inspected section&#39;s tool kits; corrected 10 improper tool etchings/8 inventory errors--100% tool accountability&quot;,\n &quot;- Deployed CTK monitor; maintained/insp&#39;d $550K test eqpmt acct--aced 3 inspections/led to 98% QA pass rate&quot;,\n &#39;- Maintained six CTKs; corrected MIL documentation errors--led to sq &amp; grp &quot;Excellent&quot; rating for 2009 UCI&#39;,\n &#39;- Committed CTK crew chief; inspected/maintained 264 tools valued at $8K--resulted in a 100% QA pass rate&#39;,\n &quot;- Eliminated excess CTK inventory; processed 60 DRMO toolbox turn-ins--reclaimed $11K/decr&#39;d CTK footprint 25%&quot;,\n &#39;- FW CDDAR program lead; verified 178 CTK items inspected/21 team mbrs trained...ensured stellar wg EAPs&#39;,\n &#39;- Demonstrated procedures to two new CTK custodians; reduced lead time, increased custodian efficiency 15%&#39;,\n &quot;- Knowledgeable! Used vast CTK experience to fix toolbox/equipment issues--increased shop&#39;s QA pass rates&quot;]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# this block is for debugging\n",
    "pageURL = 'http://www.eprbulletsafsc.com/CTK.htm'\n",
    "page = requests.get(pageURL)\n",
    "pageSoup = BeautifulSoup(page.content, 'html5lib')\n",
    "bulletScrape = pageSoup.find(id=\"page\").find_all(string=re.compile('^-\\s.*'))\n",
    "bullets = [bullet.strip() for bullet in bulletScrape]\n",
    "bullets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}