{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('webscraper': conda)",
   "display_name": "Python 3.8.5 64-bit ('webscraper': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ee1bcffc68cbb7719a6612a6e77ce6a77f4c8bd47b1c2e1622f285909b582ca8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "import multiprocessing.dummy as mp\n",
    "URL = 'http://www.eprbullets.com/'\n",
    "\n",
    "outdir = '../scrapes/'\n",
    "outfile = outdir + 'eprbullets.txt'\n",
    "homepage = requests.get(URL)\n",
    "\n",
    "# need HTML5LIB because sometimes website has errors in HTML. html5lib is very forgiving.\n",
    "homeSoup = BeautifulSoup(homepage.content,'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageList = homeSoup.find(id='mainNav').find_all('a', href=re.compile('\\w+\\.htm*'))\n",
    "pageURLs = [URL + pageItem['href'] for pageItem in pageList]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBulletsInPage(pageURL, bulletDict):\n",
    "    \n",
    "    page = requests.get(pageURL)\n",
    "    pageSoup = BeautifulSoup(page.content, 'html5lib')\n",
    "\n",
    "    # Searches #bulletmain for all strings that match regex.\n",
    "    bulletScrape = pageSoup.find(id=\"bulletmain\").find_all(string=re.compile('-\\s+.*'))\n",
    "    bulletDict[pageURL]  = [bullet.strip() for bullet in bulletScrape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multiprocessing is used to speed up the scrape. \n",
    "\n",
    "# a dict/manager is used to collect all scraped bullets during multiprocessing.  \n",
    "manager = mp.Manager()\n",
    "resultsDict = manager.dict()\n",
    "\n",
    "#running Pool() with no arguments will default to amount of cores you have... I think\n",
    "p = mp.Pool()\n",
    "\n",
    "p.starmap(getBulletsInPage, [(pageURL,resultsDict) for pageURL in pageURLs])\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "# Writing to file. Should default to clobbering.\n",
    "with open(outfile,'w',encoding='utf-8') as fileID:\n",
    "    for key in resultsDict:\n",
    "        fileID.write(f'SECTION {key} \\n')\n",
    "        for line in resultsDict[key]:\n",
    "            fileID.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is for debugging\n",
    "pageURL = 'http://www.eprbullets.com/ee.htm'\n",
    "page = requests.get(pageURL)\n",
    "pageSoup = BeautifulSoup(page.content, 'html5lib')\n",
    "bulletScrape = pageSoup.find(id=\"bulletmain\").find_all(string=re.compile('-\\s.*$'))\n",
    "bullets = [bullet.strip() for bullet in bulletScrape]"
   ]
  }
 ]
}